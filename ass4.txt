#a)Design and implement a neural network that acts as a AND classifier for binary input

import numpy as np

def step(x):
    return 1 if x >= 0 else 0

def AND(x1, x2):
    w1, w2, b = 1, 1, -1.5
    return step(w1*x1 + w2*x2 + b)

# Test
for x1 in [0,1]:
    for x2 in [0,1]:
        print(f"Input: ({x1},{x2}) → Output: {AND(x1,x2)}")









#b) Design and implement a neural network that acts as a OR classifier for binary input

def OR(x1, x2):
    w1, w2, b = 1, 1, -0.5
    return step(w1*x1 + w2*x2 + b)

for x1 in [0,1]:
    for x2 in [0,1]:
        print(f"Input: ({x1},{x2}) → Output: {OR(x1,x2)}")








#c) Design and implement a neural network that acts as a NAND classifier for binary input
#d) Design and implement a neural network that acts as a XOR classifier for binary input, Comment on the inability of this NN to classify the i/p data

def NAND(x1, x2):
    w1, w2, b = -1, -1, 1.5
    return step(w1*x1 + w2*x2 + b)

for x1 in [0,1]:
    for x2 in [0,1]:
        print(f"Input: ({x1},{x2}) → Output: {NAND(x1,x2)}")


def XOR(x1, x2):
    # Hidden layer outputs
    n1 = NAND(x1, x2)
    n2 = OR(x1, x2)
    # Final output using AND gate
    return AND(n1, n2)

for x1 in [0,1]:
    for x2 in [0,1]:
        print(f"Input: ({x1},{x2}) → Output: {XOR(x1,x2)}")










#e)Design and implement a sequential, dense neural network that acts as a classifier for the Iris dataset, tune your neural network with different hyperparameter values for learning rate, architecture and epochs

# --------------------------------------------
# Neural Network Classifier for Iris Dataset
# --------------------------------------------

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelBinarizer

# Load dataset
iris = load_iris()
X = iris.data
y = iris.target

# One-hot encode output (3 classes)
encoder = LabelBinarizer()
y = encoder.fit_transform(y)

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build Sequential model
model = Sequential([
    Dense(12, input_dim=4, activation='relu'),
    Dense(8, activation='relu'),
    Dense(3, activation='softmax')  # 3 output classes
])

# Compile model (you can change learning_rate for tuning)
model.compile(optimizer=Adam(learning_rate=0.01),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train model (you can change epochs for tuning)
model.fit(X_train, y_train, epochs=50, batch_size=8, verbose=1)

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print("Accuracy:", round(accuracy*100, 2), "%")

















#f) Design and implement a sequential, dense neural network that acts as a classifier for the diabetes dataset provided to you in class, tune your neural network with different hyperparameter values for learning rate, architecture and epochs.

# --------------------------------------------
# Neural Network Classifier for Diabetes Dataset
# --------------------------------------------

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

# Load dataset
data = load_diabetes()
X = data.data
y = data.target

# Convert target to binary (for classification)
# We'll classify as 1 if diabetes measure > mean, else 0
y = np.where(y > np.mean(y), 1, 0)

# Split data into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build Sequential model
model = Sequential([
    Dense(12, input_dim=X_train.shape[1], activation='relu'),
    Dense(8, activation='relu'),
    Dense(1, activation='sigmoid')  # Binary classification
])

# Compile model (change learning rate to tune)
model.compile(optimizer=Adam(learning_rate=0.01),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train model (change epochs to tune)
model.fit(X_train, y_train, epochs=50, batch_size=8, verbose=1)

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print("Accuracy:", round(accuracy*100, 2), "%")























#g) Design and implement a sequential, dense neural network that acts as a classifier for the heart dataset provided in class, tune your neural network with different hyperparameter values for learning rate, architecture and epochs.

# --------------------------------------------
# Neural Network Classifier for Heart Dataset
# --------------------------------------------

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load dataset (replace 'heart.csv' with your actual file)
data = pd.read_csv("heart.csv")

# Split features (X) and target (y)
X = data.drop('target', axis=1)
y = data['target']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build Sequential model
model = Sequential([
    Dense(12, input_dim=X_train.shape[1], activation='relu'),
    Dense(8, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile with different learning rate
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train with different epochs
model.fit(X_train, y_train, epochs=100, batch_size=8, verbose=1)

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print("Accuracy:", round(accuracy*100, 2), "%")





























#for AND gate


import numpy as np
def sigmoid(x):
    return 1 / (1 + np.exp(-x))
def sigmoid_derivative(x):
    return x * (1 - x)

X = np.array([[0, 0],
              [0, 1],
              [1, 0],
              [1, 1]])

y = np.array([[0],
              [0],
              [0],
              [1]])

np.random.seed(42)

weights = np.random.rand(2, 1)
bias = np.random.rand(1)
lr = 0.1

for epoch in range(10000):
    z = np.dot(X, weights) + bias
    output = sigmoid(z)
    error = y - output
    d_output = error * sigmoid_derivative(output)
    weights += np.dot(X.T, d_output) * lr
    bias += np.sum(d_output) * lr

print("Trained weights:\n", weights)
print("Trained bias:\n", bias)

for x_input in X:
    z = np.dot(x_input, weights) + bias
    pred = sigmoid(z)
    print(f"Input: {x_input}, Output: {np.round(pred)}")







































#for OR gate

import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

X = np.array([[0, 0],
              [0, 1],
              [1, 0],
              [1, 1]])

y = np.array([[0],
              [1],
              [1],
              [1]])

np.random.seed(42)

weights = np.random.rand(2, 1)
bias = np.random.rand(1)
lr = 0.1

for epoch in range(10000):
    z = np.dot(X, weights) + bias
    output = sigmoid(z)
    error = y - output
    d_output = error * sigmoid_derivative(output)
    weights += np.dot(X.T, d_output) * lr
    bias += np.sum(d_output) * lr

print("Trained weights:\n", weights)
print("Trained bias:\n", bias)

for x_input in X:
    z = np.dot(x_input, weights) + bias
    pred = sigmoid(z)
    print(f"Input: {x_input}, Output: {np.round(pred)}")
















































#for NAND gate

import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

X = np.array([[0, 0],
              [0, 1],
              [1, 0],
              [1, 1]])

y = np.array([[1],
              [1],
              [1],
              [0]])

np.random.seed(42)

weights = np.random.rand(2, 1)
bias = np.random.rand(1)
lr = 0.1

for epoch in range(10000):
    z = np.dot(X, weights) + bias
    output = sigmoid(z)
    error = y - output
    d_output = error * sigmoid_derivative(output)
    weights += np.dot(X.T, d_output) * lr
    bias += np.sum(d_output) * lr

print("Trained weights:\n", weights)
print("Trained bias:\n", bias)

for x_input in X:
    z = np.dot(x_input, weights) + bias
    pred = sigmoid(z)
    print(f"Input: {x_input}, Output: {np.round(pred)}")
































#for XOR gate

import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

X = np.array([[0, 0],
              [0, 1],
              [1, 0],
              [1, 1]])

y = np.array([[0],
              [1],
              [1],
              [0]])

np.random.seed(42)

weights = np.random.rand(2, 1)
bias = np.random.rand(1)
lr = 0.1

for epoch in range(10000):
    z = np.dot(X, weights) + bias
    output = sigmoid(z)
    error = y - output
    d_output = error * sigmoid_derivative(output)
    weights += np.dot(X.T, d_output) * lr
    bias += np.sum(d_output) * lr

print("Trained weights:\n", weights)
print("Trained bias:\n", bias)

for x_input in X:
    z = np.dot(x_input, weights) + bias
    pred = sigmoid(z)
    print(f"Input: {x_input}, Output: {np.round(pred)}")































